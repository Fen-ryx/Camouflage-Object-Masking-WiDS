{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e0c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg \n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchsummary import summary\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aa9978",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = 'cuda:0'\n",
    "else:\n",
    "    dev = 'cpu'\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39bbe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataUpload:\n",
    "    \n",
    "    def __init__(self, images_path, masks_path):\n",
    "        self.image_path = images_path\n",
    "        self.mask_path = masks_path\n",
    "        self.images_array, self.masks_array = [], []\n",
    "    \n",
    "    def loadData(self):\n",
    "        for i in tqdm(os.listdir(self.image_path)):\n",
    "            image = os.path.join(self.image_path, i)\n",
    "            image = cv.imread(image)\n",
    "            \n",
    "            self.images_array.append(image)\n",
    "        \n",
    "        for m in tqdm(os.listdir(self.mask_path)):\n",
    "            mask = os.path.join(self.mask_path, m)\n",
    "            mask = cv.imread(mask)\n",
    "            \n",
    "            self.masks_array.append(mask)\n",
    "        \n",
    "        return self.images_array, self.masks_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74042c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allAboutData(train_images_path, train_masks_path, val_images_path, val_masks_path, val_fraction=0.6):\n",
    "    \n",
    "    trainLoader = dataUpload(train_images_path, train_masks_path)\n",
    "    train_images, train_masks = trainLoader.loadData()\n",
    "    \n",
    "    val_testLoader = dataUpload(val_test_images_path, val_test_masks_path)\n",
    "    val_test_images, val_test_masks = val_testLoader.loadData()\n",
    "    \n",
    "    def val_test_split(val_fraction):\n",
    "        val_test_zip = [[image, mask] for image, mask in zip(val_test_images, val_test_masks)]\n",
    "        \n",
    "        val_size = int(val_fraction * len(val_test_zip))\n",
    "        test_size = len(val_test_zip) - val_size\n",
    "        valset, testset = torch.utils.data.random_split(val_test_zip, (val_size, test_size), generator=torch.Generator().manual_seed(0))\n",
    "        \n",
    "        val_images, val_masks = [], []\n",
    "        test_images, test_masks = [], []\n",
    "\n",
    "        for val_elem in valset:\n",
    "\n",
    "            val_images.append(val_elem[0])\n",
    "            val_masks.append(val_elem[1])\n",
    "        \n",
    "        for test_elem in testset:\n",
    "\n",
    "            test_images.append(test_elem[0])\n",
    "            test_masks.append(test_elem[1])\n",
    "        \n",
    "        return val_images, val_masks, test_images, test_masks\n",
    "    \n",
    "    val_images, val_masks, test_images, test_masks = val_test_split(val_fraction)\n",
    "    return train_images, train_masks, val_images, val_masks, test_images, test_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2633f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeImages(images, masks, height, width):\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        images[i] = cv.resize(images[i], (width, height))\n",
    "        masks[i] = cv.resize(masks[i], (width, height))\n",
    "    \n",
    "    return images, masks\n",
    "\n",
    "def toGrayScale(images, masks):\n",
    "    gray_images, gray_masks = [], []\n",
    "    for image, mask in zip(images, masks):\n",
    "        gray_images.append(cv.cvtColor(image, cv.COLOR_BGR2GRAY))\n",
    "        gray_masks.append(cv.cvtColor(mask, cv.COLOR_BGR2GRAY))\n",
    "    \n",
    "    return gray_images, gray_masks\n",
    "\n",
    "def augmentImages(images, masks, translate, rotate):\n",
    "    if translate:\n",
    "        images, masks = translateData(images, masks)\n",
    "    if rotate:\n",
    "        images, masks = rotateData(images, masks)\n",
    "    \n",
    "    return images, masks\n",
    "\n",
    "def translateData(images, masks):\n",
    "    translated_images, translated_masks = [], []\n",
    "    \n",
    "    for image, mask in zip(images, masks):\n",
    "        translated_img, translated_mask = translateImage(image, mask)\n",
    "        translated_images.append(translated_img)\n",
    "        translated_masks.append(translated_mask)\n",
    "    \n",
    "    return images + translated_images, masks + translated_masks\n",
    "\n",
    "def rotateData(images, masks):\n",
    "    rotated_images, rotated_masks = [], []\n",
    "    \n",
    "    for image, mask in zip(images, masks):\n",
    "        rot_img, rot_mask = rotateImage(image, mask)\n",
    "        rotated_images.append(rot_img)\n",
    "        rotated_masks.append(rot_mask)\n",
    "    \n",
    "    return images + rotated_images, masks + rotated_masks\n",
    "\n",
    "def translateImage(image, mask):\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    translate_value = np.random.rand() / 2\n",
    "    width_translate, height_translate = width * translate_value, height * translate_value\n",
    "    tx, ty = width / width_translate, height / height_translate\n",
    "    translation_matrix = np.array([[1, 0, tx], [0, 1, ty]], dtype=np.float32)\n",
    "    \n",
    "    translated_image = cv.warpAffine(src=image, M=translation_matrix, dsize=(width, height))\n",
    "    translated_mask = cv.warpAffine(src=mask, M=translation_matrix, dsize=(width, height))\n",
    "    \n",
    "    return translated_image, translated_mask\n",
    "\n",
    "def rotateImage(image, mask):\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    center = (width/2, height/2)\n",
    "    angle = np.random.rand() * 90\n",
    "    rotate_matrix = cv.getRotationMatrix2D(center=center, angle=angle, scale=1)\n",
    "    \n",
    "    rotated_image = cv.warpAffine(src=image, M=rotate_matrix, dsize=(width, height))\n",
    "    rotated_mask = cv.warpAffine(src=mask, M=rotate_matrix, dsize=(width, height))\n",
    "    \n",
    "    return rotated_image, rotated_mask\n",
    "\n",
    "def scaleValues(images, masks):\n",
    "    return images / 255.0, masks / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd4883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(images, masks, height, width, augment=False, translate=False, rotate=False):\n",
    "    images, masks = resizeImages(images, masks, height, width)\n",
    "    num_channels = 1\n",
    "    \n",
    "    images, masks = toGrayScale(images, masks)\n",
    "    \n",
    "    if augment:\n",
    "        images, masks = augmentImages(images, masks, translate, rotate)\n",
    "    \n",
    "    images, masks = np.array(images, dtype=np.float32), np.array(masks, dtype=np.float32)\n",
    "    images /= 255.0\n",
    "    masks /= 255.0\n",
    "    return images, masks, num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb4b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataGenerator(images, masks, batch_size, shuffle=True, train=True):\n",
    "    X, Y = images, masks\n",
    "    \n",
    "    index = 0\n",
    "    num_images = len(images)\n",
    "    indices = [*range(num_images)]\n",
    "    if shuffle:\n",
    "        random.shuffle(indices)\n",
    "    \n",
    "    while True:\n",
    "        if index >= num_images:\n",
    "            index = 0\n",
    "            if shuffle:\n",
    "                random.shuffle(indices)\n",
    "        index += 1\n",
    "        \n",
    "        for i in range(0, num_images, batch_size):\n",
    "            try:\n",
    "                x = X[indices[i:i+batch_size]]\n",
    "                y = Y[indices[i:i+batch_size]]\n",
    "            except:\n",
    "                x = X[indices[i:]]\n",
    "                y = Y[indices[i:]]\n",
    "            \n",
    "            if len(x) != batch_size or i == num_images - batch_size:\n",
    "                yield x, y, 1\n",
    "            else:\n",
    "                yield x, y, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e1bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x.float()))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86694f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_layer = convBlock(in_channels, out_channels)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        p = self.pool(x)\n",
    "        return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d87ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.convTranspose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv_layer = convBlock(out_channels * 2, out_channels)\n",
    "    \n",
    "    def forward(self, x, skip):\n",
    "        x = self.convTranspose(x)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.conv_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class U_Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encode1 = encoderBlock(1, 32)\n",
    "        self.encode2 = encoderBlock(32, 64)\n",
    "        self.encode3 = encoderBlock(64, 128)\n",
    "        self.encode4 = encoderBlock(128, 256)\n",
    "        \n",
    "        self.bottleneck = convBlock(256, 512)\n",
    "        \n",
    "        self.decode1 = decoderBlock(512, 256)\n",
    "        self.decode2 = decoderBlock(256, 128)\n",
    "        self.decode3 = decoderBlock(128, 64)\n",
    "        self.decode4 = decoderBlock(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.classify = nn.Conv2d(32, 1, kernel_size=1, padding=0)\n",
    "        self.float()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1, p1 = self.encode1(x)\n",
    "        x2, p2 = self.encode2(p1)\n",
    "        x3, p3 = self.encode3(p2)\n",
    "        x4, p4 = self.encode4(p3)\n",
    "        \n",
    "        b = self.bottleneck(p4)\n",
    "        \n",
    "        d1 = self.decode1(b, x4)\n",
    "        d2 = self.decode2(d1, x3)\n",
    "        d3 = self.decode3(d2, x2)\n",
    "        d4 = self.decode4(d3, x1)\n",
    "        \n",
    "        output = self.classify(d4)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelDefinition(model_class=U_Net, learning_rate=0.001, pretrained=True, schedule=True):\n",
    "    if pretrained:\n",
    "        model = smp.FPN(encoder_weights='imagenet', in_channels=1).to(device)\n",
    "    else:\n",
    "        model = model_class().to(device)\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    if schedule:\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=30, cooldown=10)\n",
    "        return model, loss_fn, optimizer, scheduler\n",
    "    else:\n",
    "        return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53dea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingLoop(train_generator, model, loss_fn, optimizer, num_epochs, height, width, num_channels, train_batch_size, val_images, val_masks, val_batch_size, scheduler=None):\n",
    "    train_loss, val_loss = [], []\n",
    "    train_DS, val_DS = [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss, num_images, dice_score = 0, 0, 0\n",
    "        \n",
    "        while True:\n",
    "            X, Y, count = next(train_generator)\n",
    "            X = torch.tensor(X)\n",
    "            Y = torch.tensor(Y)\n",
    "            \n",
    "            X = torch.reshape(X, (-1, 1, height, width)).to(device)\n",
    "            Y = torch.reshape(Y, (-1, 1, height, width)).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(X)\n",
    "            sigmoid = nn.Sigmoid()\n",
    "            sigmoided_output = sigmoid(output)\n",
    "            dice_score += diceScore(sigmoided_output, Y).item()\n",
    "            \n",
    "            loss = loss_fn(output, Y)\n",
    "            epoch_loss += X.size(dim=0) * loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                       \n",
    "            num_images += X.size(dim=0)            \n",
    "            if count == 1:\n",
    "                break\n",
    "        print(f\"Loss After {epoch + 1} Epochs: {epoch_loss / num_images: .6f}\")\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(epoch_loss/num_images)\n",
    "        val_generator = dataGenerator(val_images, val_masks, val_batch_size, shuffle=False, train=False)\n",
    "        valset_loss, valset_dice_score = valLoop(val_generator, loss_fn, model, height, width, val_batch_size, called_by_train=True)\n",
    "        \n",
    "        train_loss.append(epoch_loss / num_images)\n",
    "        train_DS.append(dice_score / num_images)\n",
    "        val_loss.append(valset_loss)\n",
    "        val_DS.append(valset_dice_score)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save(model.state_dict(), r'C:\\Users\\Gaurav\\IE643_Programming_Challenge\\FPN_With_Calculated_Scheduling\\FPN_GRAY_' + str(epoch+1) + '_Epochs_BCEWithLogits.pt')\n",
    "    \n",
    "    return model, train_loss, train_DS, val_loss, val_DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddce024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valLoop(val_generator, loss_fn, model, height, width, val_batch_size, called_by_train=False):\n",
    "    Y_pred = []\n",
    "    num_images, loss, dice_score = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            X, Y, count = next(val_generator)\n",
    "            \n",
    "            X = torch.tensor(X)\n",
    "            X = torch.reshape(X, (-1, 1, height, width)).to(device)\n",
    "            Y = torch.tensor(Y)\n",
    "            Y = torch.reshape(Y, (-1, 1, height, width)).to(device)\n",
    "            \n",
    "            Y_output = model(X)\n",
    "            num_images += X.size(dim=0)\n",
    "            loss += loss_fn(Y_output, Y).item() * X.size(dim=0)\n",
    "            \n",
    "            Y_output = torch.reshape(Y_output, (-1, height, width, 1))\n",
    "            sigmoid = nn.Sigmoid()\n",
    "            Y_output = sigmoid(Y_output)\n",
    "            dice_score += diceScore(Y_output, Y)\n",
    "            \n",
    "            Y_pred += list(np.reshape(Y_output.detach().cpu().numpy(), (-1, height, width)))\n",
    "            \n",
    "            if count == 1:\n",
    "                break\n",
    "    \n",
    "    if called_by_train:\n",
    "        return loss / num_images, dice_score / num_images\n",
    "    else:\n",
    "        return Y_pred, dice_score / num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c4de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diceScore(Y_output, Y):\n",
    "    gamma = 1\n",
    "    batch_size = Y_output.size(dim=0)\n",
    "    \n",
    "    model_outputs = Y_output.reshape(batch_size, -1).float()\n",
    "    original_outputs = Y.reshape(batch_size, -1).float()\n",
    "    intersection = (model_outputs * original_outputs).sum().float()\n",
    "\n",
    "    return batch_size * (2 * intersection + gamma) / (model_outputs.sum() + original_outputs.sum() + gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayOutputs(val_images, val_masks, Y_pred, num_show):\n",
    "    num_images = len(val_images)\n",
    "    indices = np.random.randint(0, num_images, size=num_show)\n",
    "    \n",
    "    for index in range(len(indices)):\n",
    "        cv.imshow('Grayscale Image', cv.resize(val_images[index], (256, 256)))\n",
    "        \n",
    "        cv.imshow('Original Mask', cv.resize(val_masks[index], (256, 256)))\n",
    "        cv.moveWindow('Original Mask', 300, 0)\n",
    "        \n",
    "        cv.imshow('Predicted Mask', cv.resize((Y_pred[index] * 255).astype(np.uint8), (256, 256)))\n",
    "        cv.moveWindow('Predicted Mask', 300, 300)\n",
    "        cv.waitKey(2000)\n",
    "    \n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c0ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = r'C:\\Users\\Gaurav\\IE643_Programming_Challenge\\Challenge_Dataset\\Images\\Train'\n",
    "train_masks_path = r'C:\\Users\\Gaurav\\IE643_Programming_Challenge\\Challenge_Dataset\\Masks\\Train'\n",
    "\n",
    "val_test_images_path = r'C:\\Users\\Gaurav\\IE643_Programming_Challenge\\Challenge_Dataset\\Images\\Validation'\n",
    "val_test_masks_path = r'C:\\Users\\Gaurav\\IE643_Programming_Challenge\\Challenge_Dataset\\Masks\\Validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af912e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 64, 64\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 200\n",
    "\n",
    "train_batch_size, val_batch_size, test_batch_size = 16, 8, 8\n",
    "val_fraction = 1.0\n",
    "shuffle = True\n",
    "\n",
    "augment = True\n",
    "translate, rotate = True, True\n",
    "\n",
    "num_show = 10\n",
    "pretrain = True\n",
    "schedule = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e66350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_masks, val_images, val_masks, test_images, test_masks = allAboutData(train_images_path, train_masks_path, val_test_images_path, val_test_masks_path, val_fraction=val_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19047411",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_masks, train_num_channels = preProcess(train_images, train_masks, height, width, augment=augment, translate=translate, rotate=rotate)\n",
    "val_images, val_masks, val_num_channels = preProcess(val_images, val_masks, height, width)\n",
    "test_images, test_masks, test_num_channels = preProcess(test_images, test_masks, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dc3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = dataGenerator(train_images, train_masks, train_batch_size, shuffle=shuffle, train=True)\n",
    "val_generator = dataGenerator(val_images, val_masks, val_batch_size, shuffle=False, train=False)\n",
    "test_generator = dataGenerator(test_images, test_masks, test_batch_size, shuffle=False, train=False)\n",
    "valUsingTrain_generator = dataGenerator(train_images, train_masks, val_batch_size, shuffle=False, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42052943",
   "metadata": {},
   "outputs": [],
   "source": [
    "if schedule:\n",
    "    model, loss_fn, optimizer, scheduler = modelDefinition(model_class=U_Net, learning_rate=learning_rate, pretrained=pretrain, schedule=schedule)\n",
    "else:\n",
    "    model, loss_fn, optimizer = modelDefinition(model_class=U_Net, learning_rate=learning_rate, pretrained=pretrain, schedule=schedule)\n",
    "    scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93435a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c61665",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_loss, train_DS, val_loss, val_DS = trainingLoop(train_generator, model, loss_fn, optimizer, num_epochs, height, width, train_num_channels, train_batch_size, val_images, val_masks, val_batch_size, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5229ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [*range(len(train_loss))]\n",
    "val_DS = [val_DS[i] * val_batch_size for i in range(len(val_DS))]\n",
    "plt.plot(X, val_DS)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Validation Dice Score')\n",
    "plt.savefig(r'C:\\Users\\Gaurav\\IE643_Programming_Challenge\\FPN_With_Calculated_Scheduling\\Val_DS_FPN_GRAY.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [*range(len(train_loss))]\n",
    "train_DS = [train_DS[i] * train_batch_size for i in range(len(train_DS))]\n",
    "plt.plot(X, train_DS)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Train Dice Score')\n",
    "plt.savefig(r'C:\\Users\\Gaurav\\IE643_Programming_Challenge\\FPN_With_Calculated_Scheduling\\Train_DS_FPN_GRAY.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd903a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [*range(len(train_loss))]\n",
    "plt.plot(X, train_loss)\n",
    "plt.plot(X, val_loss)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend((['Train Loss', 'Val Loss']))\n",
    "plt.savefig(r'C:\\Users\\Gaurav\\IE643_Programming_Challenge\\FPN_With_Calculated_Scheduling\\Train_Val_Loss_FPN_GRAY.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [*range(len(train_loss))]\n",
    "plt.plot(X, val_loss)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.savefig(r'C:\\Users\\Gaurav\\IE643_Programming_Challenge\\FPN_With_Calculated_Scheduling\\Val_Loss_FPN_GRAY.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [*range(len(train_loss))]\n",
    "plt.plot(X, train_loss)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.savefig(r'C:\\Users\\Gaurav\\IE643_Programming_Challenge\\FPN_With_Calculated_Scheduling\\Train_Loss_FPN_GRAY.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a2dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_DS, val_loss, val_DS = fixLists(train_loss), fixLists(train_DS), fixLists(val_loss), fixLists(val_DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixLists(input_list):\n",
    "    fixed_list = []\n",
    "    for elem in input_list:\n",
    "        try:\n",
    "            fixed_list.append(elem.detach().cpu().item())\n",
    "        except:\n",
    "            fixed_list.append(elem)\n",
    "    return fixed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736eb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred, dice_score = valLoop(val_generator, loss_fn, model, height, width, val_batch_size, called_by_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd15a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayOutputs(val_images, val_masks, Y_pred, num_show=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
